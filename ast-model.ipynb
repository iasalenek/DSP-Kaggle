{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"DATA_DIR = '../input/hse-acoustic-event-detection-2022'\n\ntrain_data_dir = 'audio_train/train'\ntrain_meta_fname = 'train.csv'\n\ntest_data_dir = 'audio_test/test'\ntest_meta_fname = 'sample_submission.csv'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-13T22:29:32.343443Z","iopub.execute_input":"2022-11-13T22:29:32.344114Z","iopub.status.idle":"2022-11-13T22:29:32.377490Z","shell.execute_reply.started":"2022-11-13T22:29:32.344017Z","shell.execute_reply":"2022-11-13T22:29:32.376660Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"! git clone -q https://github.com/YuanGongND/ast\n! pip install -q timm==0.4.5\n! pip install -q wget\n\nimport sys\nimport os, csv, argparse, wget\nimport torch, torchaudio, timm\nimport numpy as np\nfrom torch.cuda.amp import autocast\nimport IPython\n\nfrom torch.utils.data import Dataset, DataLoader\n\nsys.path.append('./ast')\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nBATCH_SIZE = 16","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:29:32.381980Z","iopub.execute_input":"2022-11-13T22:29:32.382809Z","iopub.status.idle":"2022-11-13T22:30:00.977040Z","shell.execute_reply.started":"2022-11-13T22:29:32.382774Z","shell.execute_reply":"2022-11-13T22:30:00.975799Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport torch.nn as nn\n\nfrom sklearn.metrics import f1_score\n\ntrain_loss_fn = nn.CrossEntropyLoss()\n\ndef val_loss_fn(predictions, target):\n    return f1_score(predictions, target, average='macro')","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:30:00.982073Z","iopub.execute_input":"2022-11-13T22:30:00.984901Z","iopub.status.idle":"2022-11-13T22:30:01.445700Z","shell.execute_reply.started":"2022-11-13T22:30:00.984858Z","shell.execute_reply":"2022-11-13T22:30:01.444729Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Feature extractor\ndef make_features(waveform, sr, mel_bins=128, target_length=1024):\n    \n    assert sr == 16000, 'input audio sampling rate must be 16kHz'\n\n    fbank = torchaudio.compliance.kaldi.fbank(\n        waveform, htk_compat=True, sample_frequency=sr, use_energy=False,\n        window_type='hanning', num_mel_bins=mel_bins, dither=0.0, frame_shift=10)\n\n    n_frames = fbank.shape[0]\n\n    p = target_length - n_frames\n    if p > 0:\n        m = torch.nn.ZeroPad2d((0, 0, 0, p))\n        fbank = m(fbank)\n    elif p < 0:\n        fbank = fbank[0:target_length, :]\n\n    fbank = (fbank - (-4.2677393)) / (4.5689974 * 2)\n    return fbank","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:30:01.448221Z","iopub.execute_input":"2022-11-13T22:30:01.448602Z","iopub.status.idle":"2022-11-13T22:30:01.456829Z","shell.execute_reply.started":"2022-11-13T22:30:01.448546Z","shell.execute_reply":"2022-11-13T22:30:01.455845Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from src.models import ASTModel\n\n# Отрезаем mlp_head у модели (чтобы хоть что-то обучить)\nclass MyASTModel(ASTModel):\n    \n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.mlp_head = None\n    \n    @autocast()\n    def forward(self, x):\n        \"\"\"\n        :param x: the input spectrogram, expected shape: (batch_size, time_frame_num, frequency_bins), e.g., (12, 1024, 128)\n        :return: prediction\n        \"\"\"\n        # expect input x = (batch_size, time_frame_num, frequency_bins), e.g., (12, 1024, 128)\n        x = x.unsqueeze(1)\n        x = x.transpose(2, 3)\n\n        B = x.shape[0]\n        x = self.v.patch_embed(x)\n        cls_tokens = self.v.cls_token.expand(B, -1, -1)\n        dist_token = self.v.dist_token.expand(B, -1, -1)\n        x = torch.cat((cls_tokens, dist_token, x), dim=1)\n        x = x + self.v.pos_embed\n        x = self.v.pos_drop(x)\n        for blk in self.v.blocks:\n            x = blk(x)\n        x = self.v.norm(x)\n        x = (x[:, 0] + x[:, 1]) / 2\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:30:01.458056Z","iopub.execute_input":"2022-11-13T22:30:01.459054Z","iopub.status.idle":"2022-11-13T22:30:01.473081Z","shell.execute_reply.started":"2022-11-13T22:30:01.459015Z","shell.execute_reply":"2022-11-13T22:30:01.472076Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Загружаем веса модели\ncheckpoint_path = 'ast/pretrained_models/audio_mdl.pth'\n\naudioset_mdl_url = 'https://www.dropbox.com/s/cv4knew8mvbrnvq/audioset_0.4593.pth?dl=1'\nif os.path.exists(checkpoint_path) == False:\n    print('Downloading weights...')\n    wget.download(audioset_mdl_url, out=checkpoint_path)\n    print('Complete!')","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:30:01.474425Z","iopub.execute_input":"2022-11-13T22:30:01.475039Z","iopub.status.idle":"2022-11-13T22:30:10.991951Z","shell.execute_reply.started":"2022-11-13T22:30:01.475000Z","shell.execute_reply":"2022-11-13T22:30:10.990844Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading weights...\nComplete!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Входные и выходные размерности предобученной модели\ninput_tdim = 1024\noutput_dim = 527\n\n# Архитектура, соответствующая загруженным весам\nast_mdl = MyASTModel(label_dim=output_dim, input_tdim=input_tdim, imagenet_pretrain=False, audioset_pretrain=False)\ncheckpoint = torch.load(checkpoint_path, map_location=DEVICE)\n\n# Оборачиваем модель в DataParallel, как в оригинальной работе (для загрузки весов)\naudio_model = torch.nn.DataParallel(ast_mdl, device_ids=[0])\naudio_model.load_state_dict(checkpoint)\naudio_model = audio_model.to(DEVICE)\naudio_model.eval();","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:30:10.993567Z","iopub.execute_input":"2022-11-13T22:30:10.993996Z","iopub.status.idle":"2022-11-13T22:30:16.086602Z","shell.execute_reply.started":"2022-11-13T22:30:10.993957Z","shell.execute_reply":"2022-11-13T22:30:16.085637Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"---------------AST Model Summary---------------\nImageNet pretraining: False, AudioSet pretraining: False\nfrequncey stride=10, time stride=10\nnumber of patches=1212\n","output_type":"stream"}]},{"cell_type":"code","source":"class AST_train_dataset(Dataset):\n    def __init__(self, data_dir: str, meta: pd.DataFrame, transforms=None):\n        \n        # Имена фалов в датасете\n        self.filenames = meta['fname'].tolist()\n                \n        # Создаем словарь меток файлов\n        labels_dict = dict()\n        \n        for filename, label in zip(meta['fname'], meta['label_encoded']):\n            \n            labels_dict[filename] = label\n\n        self.labels_dict = labels_dict\n        self.transforms = transforms\n        self.data_dir = data_dir\n        \n    def __getitem__(self, index):\n        \n        filename = self.filenames[index]\n        \n        # Загружвем wav файл и считаем фходные фичи модели\n        waveform, sr = torchaudio.load(\n            Path(DATA_DIR, self.data_dir, filename))\n        \n        # Если даны преобразования, пременяем их к wav файлу\n        if self.transforms is not None:\n            waveform = self.transforms(waveform)\n            \n        frets = make_features(waveform, sr)\n        label = self.labels_dict[filename]\n        \n        return {'frets': frets, \n                'label': label}\n    \n    def __len__(self):\n        return len(self.filenames)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:30:16.087974Z","iopub.execute_input":"2022-11-13T22:30:16.088968Z","iopub.status.idle":"2022-11-13T22:30:16.099850Z","shell.execute_reply.started":"2022-11-13T22:30:16.088925Z","shell.execute_reply":"2022-11-13T22:30:16.098595Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class AST_test_dataset(Dataset):\n    def __init__(self, data_dir: str, meta: pd.DataFrame):\n        \n        # Имена фалов в датасете\n        self.filenames = meta['fname'].tolist()\n        self.data_dir = data_dir\n        \n    def __getitem__(self, index):\n        \n        filename = self.filenames[index]\n        \n        # Загружвем wav файл и считаем фходные фичи модели\n        waveform, sr = torchaudio.load(\n            Path(DATA_DIR, self.data_dir, filename))\n            \n        frets = make_features(waveform, sr)\n        \n        return {'frets': frets}\n    \n    def __len__(self):\n        return len(self.filenames)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:30:16.101450Z","iopub.execute_input":"2022-11-13T22:30:16.102032Z","iopub.status.idle":"2022-11-13T22:30:16.112951Z","shell.execute_reply.started":"2022-11-13T22:30:16.101991Z","shell.execute_reply":"2022-11-13T22:30:16.111950Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef extract_features(audio_model, dataloader, return_labels=True):\n    \n    model_outputs = []\n    labels = []\n    \n    pbar = tqdm(iterable=dataloader)\n\n    for batch in pbar:\n\n        frets = batch['frets'].to(DEVICE)\n\n        with torch.no_grad():\n            with autocast():\n                output = audio_model.forward(frets)\n\n        model_outputs.append(output.cpu().detach().numpy())\n\n        if return_labels:\n            labels += batch['label'].tolist()\n            \n    return np.vstack(model_outputs), np.array(labels)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:30:16.116227Z","iopub.execute_input":"2022-11-13T22:30:16.116784Z","iopub.status.idle":"2022-11-13T22:30:16.126729Z","shell.execute_reply.started":"2022-11-13T22:30:16.116745Z","shell.execute_reply":"2022-11-13T22:30:16.125828Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    \n    # Загружаем csv\n    df_train_val = pd.read_csv(Path(DATA_DIR, train_meta_fname))\n    df_test = pd.read_csv(Path(DATA_DIR, test_meta_fname))\n    \n    # Задаем метки классов\n    n_classes = df_train_val.label.nunique()\n    classes_dict = {cl:i for i,cl in enumerate(df_train_val.label.unique())}\n    df_train_val['label_encoded'] = df_train_val.label.map(classes_dict)\n    \n    # Делим на train и val (по label_encoded)\n    df_train, df_val = train_test_split(df_train_val, test_size=0.2, stratify=df_train_val['label_encoded'])\n    print(f'df_train length: {len(df_train)}')\n    print(f'df_val length:   {len(df_val)}')\n    print(f'df_test length:  {len(df_test)}')\n    \n    # Создаем датасеты и даталодеры\n    train_dataset = AST_train_dataset(train_data_dir, df_train)\n    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n    \n    val_dataset = AST_train_dataset(train_data_dir, df_val)\n    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n    \n    test_dataset = AST_test_dataset(test_data_dir, df_test)\n    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n    \n    # Cоздаем директорию для сохранения извлеченных фичей\n    !mkdir features\n\n    # Извлекаем фичи и сохраням\n    train_features, train_labels = extract_features(audio_model, train_dataloader)\n    np.save('features/train_features', train_features)\n    np.save('features/train_labels', train_labels)\n\n    val_features, val_labels = extract_features(audio_model, val_dataloader)\n    np.save('features/val_features', val_features)\n    np.save('features/val_labels', val_labels)\n    \n    test_features, _ =  extract_features(audio_model, test_dataloader, return_labels=False)\n    np.save('features/test_features', test_features)\n    \n    # Архивируем для скачивния\n    !zip -r features.zip features","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:53:47.524890Z","iopub.execute_input":"2022-11-13T22:53:47.525252Z","iopub.status.idle":"2022-11-13T22:57:35.784057Z","shell.execute_reply.started":"2022-11-13T22:53:47.525220Z","shell.execute_reply":"2022-11-13T22:57:35.782927Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"df_train length: 4546\ndf_val length:   1137\ndf_test length:  3790\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 237/237 [03:45<00:00,  1.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"updating: features/ (stored 0%)\nupdating: features/test_features.npy (deflated 8%)\nupdating: features/val_labels.npy (deflated 83%)\nupdating: features/val_features.npy (deflated 8%)\nupdating: features/train_features.npy (deflated 8%)\nupdating: features/train_labels.npy (deflated 85%)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### MLP Classifier (отдельный ноутбук)","metadata":{}},{"cell_type":"code","source":"class MLP_dataset(Dataset):\n    def __init__(self, features, labels):\n        \n        self.features = features\n        self.labels = labels\n        \n    def __getitem__(self, index):\n        \n        return {'features': self.features[index], \n                'labels': self.labels[index]}\n    \n    def __len__(self):\n        return len(self.labels)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:57:44.511822Z","iopub.execute_input":"2022-11-13T22:57:44.512211Z","iopub.status.idle":"2022-11-13T22:57:44.519119Z","shell.execute_reply.started":"2022-11-13T22:57:44.512172Z","shell.execute_reply":"2022-11-13T22:57:44.517971Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, optimizer,\n                dataloader, loss_fn, epoch):\n        \n    total_loss = 0\n    processed = 0\n\n    pbar = tqdm(iterable=dataloader,\n                desc=f'epoch {epoch}')\n\n    for batch in pbar:\n        features = batch['features'].to(DEVICE)\n        labels = batch['labels'].to(DEVICE)\n\n        output = model(features)\n        loss = loss_fn(output, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item() * len(batch)\n        processed += len(batch)\n\n        pbar.set_postfix({'batch loss': total_loss / processed})","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:57:45.508865Z","iopub.execute_input":"2022-11-13T22:57:45.509185Z","iopub.status.idle":"2022-11-13T22:57:45.517477Z","shell.execute_reply.started":"2022-11-13T22:57:45.509155Z","shell.execute_reply":"2022-11-13T22:57:45.516354Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef evaluate_epoch(model, dataloader, epoch):\n    \n    model.eval()\n    \n    pbar = tqdm(iterable=dataloader,\n                desc=f'epoch {epoch}')\n    \n    predictions = []\n    targets = []\n\n    for batch in pbar:\n        features = batch['features'].to(DEVICE)\n        labels = batch['labels']\n\n        output = model(features)\n        \n        predictions += torch.argmax(output, axis=1).cpu().detach().tolist()\n        targets += labels.tolist()\n        \n    print(val_loss_fn(predictions, targets))","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:57:46.373942Z","iopub.execute_input":"2022-11-13T22:57:46.374902Z","iopub.status.idle":"2022-11-13T22:57:46.381908Z","shell.execute_reply.started":"2022-11-13T22:57:46.374857Z","shell.execute_reply":"2022-11-13T22:57:46.380779Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef predict(model, dataloader, epoch):\n    \n    model.eval()\n    \n    pbar = tqdm(iterable=dataloader,\n                desc=f'epoch {epoch}')\n    \n    predictions = []\n\n    for batch in pbar:\n        features = batch['features'].to(DEVICE)\n        output = model(features)\n        \n        predictions += torch.argmax(output, axis=1).cpu().detach().tolist()\n        \n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:57:46.873181Z","iopub.execute_input":"2022-11-13T22:57:46.873470Z","iopub.status.idle":"2022-11-13T22:57:46.879749Z","shell.execute_reply.started":"2022-11-13T22:57:46.873442Z","shell.execute_reply":"2022-11-13T22:57:46.878642Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def train(model, optimizer, \n          train_dataloader, val_dataloader,\n          train_loss_fn, val_loss_fn,\n          n_epochs: int = 51, eval_every: int = 5):\n    \n    for epoch in range(n_epochs):\n        \n        train_epoch(model, optimizer, train_dataloader, train_loss_fn, epoch)\n        \n        if eval_every is not None and epoch % eval_every == 0:\n            evaluate_epoch(model, val_dataloader, epoch)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:57:47.307213Z","iopub.execute_input":"2022-11-13T22:57:47.307859Z","iopub.status.idle":"2022-11-13T22:57:47.314330Z","shell.execute_reply.started":"2022-11-13T22:57:47.307819Z","shell.execute_reply":"2022-11-13T22:57:47.313361Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"classifier = nn.Sequential(\n    nn.Linear(768, 256),\n    nn.ReLU(),\n    nn.Linear(256, 41)\n).to(DEVICE)\n\noptimizer = torch.optim.Adam(classifier.parameters())\n\nMLP_train_dataset = MLP_dataset(train_features, train_labels)\nMLP_train_dataloader = DataLoader(MLP_train_dataset, batch_size=4546)\n\nMLP_val_dataset = MLP_dataset(val_features, val_labels)\nMLP_val_dataloader = DataLoader(MLP_val_dataset, batch_size=256)\n\ntrain(classifier, optimizer,\n      MLP_train_dataloader, MLP_val_dataloader,\n      train_loss_fn, val_loss_fn)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:57:47.759177Z","iopub.execute_input":"2022-11-13T22:57:47.759938Z","iopub.status.idle":"2022-11-13T22:57:49.667235Z","shell.execute_reply.started":"2022-11-13T22:57:47.759899Z","shell.execute_reply":"2022-11-13T22:57:49.666260Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"epoch 0: 100%|██████████| 1/1 [00:00<00:00, 11.51it/s, batch loss=3.8]\nepoch 0: 100%|██████████| 5/5 [00:00<00:00, 355.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.14144103708118091\n","output_type":"stream"},{"name":"stderr","text":"epoch 1: 100%|██████████| 1/1 [00:00<00:00, 20.57it/s, batch loss=3.41]\nepoch 2: 100%|██████████| 1/1 [00:00<00:00, 26.56it/s, batch loss=3.08]\nepoch 3: 100%|██████████| 1/1 [00:00<00:00, 28.50it/s, batch loss=2.74]\nepoch 4: 100%|██████████| 1/1 [00:00<00:00, 29.06it/s, batch loss=2.41]\nepoch 5: 100%|██████████| 1/1 [00:00<00:00, 29.52it/s, batch loss=2.09]\nepoch 5: 100%|██████████| 5/5 [00:00<00:00, 452.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.4999729935277006\n","output_type":"stream"},{"name":"stderr","text":"epoch 6: 100%|██████████| 1/1 [00:00<00:00, 29.47it/s, batch loss=1.81]\nepoch 7: 100%|██████████| 1/1 [00:00<00:00, 27.78it/s, batch loss=1.57]\nepoch 8: 100%|██████████| 1/1 [00:00<00:00, 29.45it/s, batch loss=1.37]\nepoch 9: 100%|██████████| 1/1 [00:00<00:00, 29.79it/s, batch loss=1.2]\nepoch 10: 100%|██████████| 1/1 [00:00<00:00, 29.31it/s, batch loss=1.06]\nepoch 10: 100%|██████████| 5/5 [00:00<00:00, 490.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.7374544405497462\n","output_type":"stream"},{"name":"stderr","text":"epoch 11: 100%|██████████| 1/1 [00:00<00:00, 29.46it/s, batch loss=0.96]\nepoch 12: 100%|██████████| 1/1 [00:00<00:00, 29.62it/s, batch loss=0.881]\nepoch 13: 100%|██████████| 1/1 [00:00<00:00, 29.88it/s, batch loss=0.818]\nepoch 14: 100%|██████████| 1/1 [00:00<00:00, 29.74it/s, batch loss=0.763]\nepoch 15: 100%|██████████| 1/1 [00:00<00:00, 29.78it/s, batch loss=0.718]\nepoch 15: 100%|██████████| 5/5 [00:00<00:00, 484.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.7756435359611215\n","output_type":"stream"},{"name":"stderr","text":"epoch 16: 100%|██████████| 1/1 [00:00<00:00, 42.73it/s, batch loss=0.681]\nepoch 17: 100%|██████████| 1/1 [00:00<00:00, 43.48it/s, batch loss=0.651]\nepoch 18: 100%|██████████| 1/1 [00:00<00:00, 42.33it/s, batch loss=0.625]\nepoch 19: 100%|██████████| 1/1 [00:00<00:00, 41.53it/s, batch loss=0.6]\nepoch 20: 100%|██████████| 1/1 [00:00<00:00, 42.17it/s, batch loss=0.576]\nepoch 20: 100%|██████████| 5/5 [00:00<00:00, 516.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.7928821778830569\n","output_type":"stream"},{"name":"stderr","text":"epoch 21: 100%|██████████| 1/1 [00:00<00:00, 45.97it/s, batch loss=0.554]\nepoch 22: 100%|██████████| 1/1 [00:00<00:00, 43.71it/s, batch loss=0.534]\nepoch 23: 100%|██████████| 1/1 [00:00<00:00, 45.19it/s, batch loss=0.517]\nepoch 24: 100%|██████████| 1/1 [00:00<00:00, 43.49it/s, batch loss=0.501]\nepoch 25: 100%|██████████| 1/1 [00:00<00:00, 46.03it/s, batch loss=0.485]\nepoch 25: 100%|██████████| 5/5 [00:00<00:00, 552.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.8116656659595628\n","output_type":"stream"},{"name":"stderr","text":"epoch 26: 100%|██████████| 1/1 [00:00<00:00, 44.35it/s, batch loss=0.47]\nepoch 27: 100%|██████████| 1/1 [00:00<00:00, 40.81it/s, batch loss=0.454]\nepoch 28: 100%|██████████| 1/1 [00:00<00:00, 42.66it/s, batch loss=0.44]\nepoch 29: 100%|██████████| 1/1 [00:00<00:00, 43.49it/s, batch loss=0.426]\nepoch 30: 100%|██████████| 1/1 [00:00<00:00, 42.64it/s, batch loss=0.413]\nepoch 30: 100%|██████████| 5/5 [00:00<00:00, 555.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.8251139822617777\n","output_type":"stream"},{"name":"stderr","text":"epoch 31: 100%|██████████| 1/1 [00:00<00:00, 41.44it/s, batch loss=0.401]\nepoch 32: 100%|██████████| 1/1 [00:00<00:00, 43.48it/s, batch loss=0.389]\nepoch 33: 100%|██████████| 1/1 [00:00<00:00, 43.92it/s, batch loss=0.377]\nepoch 34: 100%|██████████| 1/1 [00:00<00:00, 42.19it/s, batch loss=0.367]\nepoch 35: 100%|██████████| 1/1 [00:00<00:00, 44.89it/s, batch loss=0.356]\nepoch 35: 100%|██████████| 5/5 [00:00<00:00, 620.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.826497140542408\n","output_type":"stream"},{"name":"stderr","text":"epoch 36: 100%|██████████| 1/1 [00:00<00:00, 45.03it/s, batch loss=0.345]\nepoch 37: 100%|██████████| 1/1 [00:00<00:00, 43.13it/s, batch loss=0.335]\nepoch 38: 100%|██████████| 1/1 [00:00<00:00, 42.43it/s, batch loss=0.324]\nepoch 39: 100%|██████████| 1/1 [00:00<00:00, 41.54it/s, batch loss=0.315]\nepoch 40: 100%|██████████| 1/1 [00:00<00:00, 45.05it/s, batch loss=0.305]\nepoch 40: 100%|██████████| 5/5 [00:00<00:00, 613.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.8247355978442672\n","output_type":"stream"},{"name":"stderr","text":"epoch 41: 100%|██████████| 1/1 [00:00<00:00, 43.78it/s, batch loss=0.296]\nepoch 42: 100%|██████████| 1/1 [00:00<00:00, 44.54it/s, batch loss=0.287]\nepoch 43: 100%|██████████| 1/1 [00:00<00:00, 43.14it/s, batch loss=0.279]\nepoch 44: 100%|██████████| 1/1 [00:00<00:00, 41.96it/s, batch loss=0.27]\nepoch 45: 100%|██████████| 1/1 [00:00<00:00, 45.24it/s, batch loss=0.263]\nepoch 45: 100%|██████████| 5/5 [00:00<00:00, 525.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"0.8233587290245713\n","output_type":"stream"},{"name":"stderr","text":"epoch 46: 100%|██████████| 1/1 [00:00<00:00, 43.79it/s, batch loss=0.255]\nepoch 47: 100%|██████████| 1/1 [00:00<00:00, 45.05it/s, batch loss=0.248]\nepoch 48: 100%|██████████| 1/1 [00:00<00:00, 45.18it/s, batch loss=0.24]\nepoch 49: 100%|██████████| 1/1 [00:00<00:00, 42.88it/s, batch loss=0.233]\nepoch 50: 100%|██████████| 1/1 [00:00<00:00, 44.48it/s, batch loss=0.227]\nepoch 50: 100%|██████████| 5/5 [00:00<00:00, 614.14it/s]","output_type":"stream"},{"name":"stdout","text":"0.8243328745303161\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"class MLPTestDataset(Dataset):\n    def __init__(self, features):\n        \n        self.features = features\n        \n    def __getitem__(self, index):\n        \n        return {'features': self.features[index]}\n    \n    def __len__(self):\n        return len(self.features)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:58:06.696460Z","iopub.execute_input":"2022-11-13T22:58:06.697445Z","iopub.status.idle":"2022-11-13T22:58:06.703917Z","shell.execute_reply.started":"2022-11-13T22:58:06.697408Z","shell.execute_reply":"2022-11-13T22:58:06.702625Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"MLP_test_dataset = MLPTestDataset(test_features)\nMLP_test_dataloader = DataLoader(MLP_test_dataset, batch_size = 128)\n\npredictions = predict(classifier, MLP_test_dataloader, epoch=0)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:58:14.422688Z","iopub.execute_input":"2022-11-13T22:58:14.423044Z","iopub.status.idle":"2022-11-13T22:58:14.460216Z","shell.execute_reply.started":"2022-11-13T22:58:14.423012Z","shell.execute_reply":"2022-11-13T22:58:14.459180Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"epoch 0: 100%|██████████| 30/30 [00:00<00:00, 1055.92it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from copy import copy\nsubmission = df_test.copy()\nsubmission['label'] = predictions\ndecoder = {v: k for (k, v) in classes_dict.items()}\nsubmission['label'] = submission['label'].map(decoder)\nsubmission.to_csv('submission.csv', index=None)","metadata":{"execution":{"iopub.status.busy":"2022-11-13T22:58:19.327051Z","iopub.execute_input":"2022-11-13T22:58:19.327483Z","iopub.status.idle":"2022-11-13T22:58:19.357637Z","shell.execute_reply.started":"2022-11-13T22:58:19.327444Z","shell.execute_reply":"2022-11-13T22:58:19.356782Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}